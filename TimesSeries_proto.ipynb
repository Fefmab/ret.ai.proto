{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pronostico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Paqueteria a utilizar\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns # visualization library\n",
    "import matplotlib.pyplot as plt # visualization library\n",
    "#import plotly.plotly as py # visualization library\n",
    "from plotly.offline import init_notebook_mode, iplot # plotly offline mode\n",
    "init_notebook_mode(connected=True) \n",
    "import plotly.graph_objs as go # plotly graphical object\n",
    "\n",
    "import chart_studio.plotly as py\n",
    "\n",
    "import warnings        \n",
    "# ignore filters\n",
    "warnings.filterwarnings(\"ignore\") # if there is a warning after some codes, this will avoid us to see them.\n",
    "plt.style.use('ggplot') # style of plots. ggplot is one of the most used style, I also like it.\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/mafer/Documents/.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Borramos columnas con na\n",
    "df = df[pd.isna(df.column)==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unused features\n",
    "drop_list = ['columns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(drop_list, axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['column'].value_counts())\n",
    "plt.figure(figsize=(22,10))\n",
    "sns.countplot(df['column'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series prediction with ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean variable\n",
    "plt.figure(figsize=(22,10))\n",
    "plt.plot(variable_bin.Date,variable_bin.variable)\n",
    "plt.title(\"Mean variable\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Mean variable\")\n",
    "plt.show()\n",
    "\n",
    "# lets create time series from variable \n",
    "timeSeries = variable_bin.loc[:, [\"Date\",\"Variable\"]]\n",
    "timeSeries.index = timeSeries.Date\n",
    "ts = timeSeries.drop(\"Date\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets check stationary of time series. We can check stationarity using the following methods:\n",
    "# -Plotting Rolling Statistics: We have a window lets say window size is 6 and then we find rolling mean and variance to check \n",
    "#     stationary.\n",
    "# -Dickey-Fuller Test: The test results comprise of a Test Statistic and some Critical Values for difference confidence levels. \n",
    "#     If the test statistic is less than the critical value, we can say that time series is stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adfuller library \n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "# check_adfuller\n",
    "def check_adfuller(ts):\n",
    "    # Dickey-Fuller test\n",
    "    result = adfuller(ts, autolag='AIC')\n",
    "    print('Test statistic: ' , result[0])\n",
    "    print('p-value: '  ,result[1])\n",
    "    print('Critical Values:' ,result[4])\n",
    "# check_mean_std\n",
    "def check_mean_std(ts):\n",
    "    #Rolling statistics\n",
    "    rolmean = ts.rolling(window=6).mean()\n",
    "    rolstd = ts.rolling(window=6).std()\n",
    "    plt.figure(figsize=(22,10))   \n",
    "    orig = plt.plot(ts, color='red',label='Original')\n",
    "    mean = plt.plot(rolmean, color='black', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='green', label = 'Rolling Std')\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Mean Variable\")\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "# check stationary: mean, variance(std)and adfuller test\n",
    "check_mean_std(ts)\n",
    "check_adfuller(ts.MeanVariable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a time series stationary? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "As we mentioned before, there are 2 reasons behind non-stationarity of time series:\n",
    "-Trend: varying mean over time. We need constant mean for stationary of time series.\n",
    "-Seasonality: variations at specific time. We need constant variations for stationary of time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "First solve trend(constant mean) problem\n",
    "Most popular method is moving average.\n",
    "Moving average: We have window that take the average over the past 'n' sample. 'n' is window size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving average method\n",
    "window_size = 6 #6 días atrás \n",
    "moving_avg = ts.rolling(6).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22,10))\n",
    "plt.plot(ts, color = \"red\",label = \"Original\")\n",
    "plt.plot(moving_avg, color='black', label = \"moving_avg_mean\")\n",
    "plt.title(\"Mean Variable\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Mean Variable\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_moving_avg_diff = ts - moving_avg\n",
    "ts_moving_avg_diff.dropna(inplace=True) # first 6 is nan value due to window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'check_mean_std' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-ee58c1a6c18c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# check stationary: mean, variance(std)and adfuller test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcheck_mean_std\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts_moving_avg_diff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcheck_adfuller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts_moving_avg_diff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMeanVariable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'check_mean_std' is not defined"
     ]
    }
   ],
   "source": [
    "# check stationary: mean, variance(std)and adfuller test\n",
    "check_mean_std(ts_moving_avg_diff)\n",
    "check_adfuller(ts_moving_avg_diff.MeanVariable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hasta este punto podría ser estacionaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Differencing method: It is one of the most common method. Idea is that take difference between time series \n",
    "and shifted time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# differencing method\n",
    "ts_diff = ts - ts.shift()\n",
    "plt.figure(figsize=(22,10))\n",
    "plt.plot(ts_diff)\n",
    "plt.title(\"Differencing method\") \n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Differencing Mean Variable\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_diff.dropna(inplace=True) # due to shifting there is nan values\n",
    "# check stationary: mean, variance(std)and adfuller test\n",
    "check_mean_std(ts_diff)\n",
    "check_adfuller(ts_diff.MeanVariable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Forecasting a Time Series\n",
    "-Two different methodsthat are moving average and differencing methods to avoid trend and seasonality problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-7ba98dcad1f4>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-7ba98dcad1f4>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    Prediction method is ARIMA that is Auto-Regressive Integrated Moving Averages.\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Prediction method is ARIMA that is Auto-Regressive Integrated Moving Averages.\n",
    "AR: Auto-Regressive (p): AR terms are just lags of dependent variable. For example lets say p is 3, \n",
    "        we will use x(t-1), x(t-2) and x(t-3) to predict x(t)\n",
    "I: Integrated (d): These are the number of nonseasonal differences. For example, in our case we take the first order \n",
    "        difference. So we pass that variable and put d=0\n",
    "MA: Moving Averages (q): MA terms are lagged forecast errors in prediction equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forecasting a time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ARIMA forecasting for a stationary time series is nothing but a linear (like a linear regression) equation. The predictors depend on the parameters (p,d,q) of the ARIMA model:\n",
    "\n",
    "1. Number of AR (Auto-Regressive) terms (p): AR terms are just lags of dependent variable. For instance if p is 5, the predictors for x(t) will be x(t-1)….x(t-5).\n",
    "2. Number of MA (Moving Average) terms (q): MA terms are lagged forecast errors in prediction equation. For instance if q is 5, the predictors for x(t) will be e(t-1)….e(t-5) where e(i) is the difference between the moving average at ith instant and actual value.\n",
    "3. Number of Differences (d): These are the number of nonseasonal differences, i.e. in this case we took the first order difference. So either we can pass that variable and put d=0 or pass the original variable and put d=1. Both will generate same results.\n",
    "\n",
    "An importance concern here is how to determine the value of ‘p’ and ‘q’. We use two plots to determine these numbers.\n",
    "\n",
    "1. Autocorrelation Function (ACF): It is a measure of the correlation between the TS with a lagged version of itself. For instance at lag 5, ACF would compare series at time instant ‘t1’…’t2’ with series at instant ‘t1-5’…’t2-5’ (t1-5 and t2 being end points).\n",
    "2. Partial Autocorrelation Function (PACF): This measures the correlation between the TS with a lagged version of itself but after eliminating the variations already explained by the intervening comparisons. Eg at lag 5, it will check the correlation but remove the effects already explained by lags 1 to 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos también un diagrama de autocorrelación de la serie temporal. Esto también está integrado en Pandas. El siguiente ejemplo traza la autocorrelación para un gran número de retrasos en la serie de tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACF plot\n",
    "pd.plotting.autocorrelation_plot(ts_log_diff) #Revisar en que punto/rezago de la grafica la autocorrelacion es significativa \n",
    "                                              #(mayor a .5) para fijar ahi el lag value = p\n",
    "                                              \n",
    "\n",
    "#plt.figure(figsize=(12, 6))\n",
    "#pd.plotting.autocorrelation_plot(series)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In this plot, the two dotted lines on either sides of 0 are the confidence interevals. These can be used to determine the ‘p’ and ‘q’ values as:\n",
    "\n",
    "p – The lag value where the PACF chart crosses the upper confidence interval for the first time (p=2).\n",
    "\n",
    "q – The lag value where the ACF chart crosses the upper confidence interval for the first time(q=2).\n",
    "\n",
    "Now, lets make 3 different ARIMA models considering individual as well as combined effects. We will also print the RSS for each. Please note that here RSS is for the values of residuals and not actual series.\n",
    "\n",
    "We need to load the ARIMA model first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necesitamos entender bien ACF y PACF para saber el orden de p,d,q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defina el modelo llamando a ARIMA () y pasando los parámetros p, d y q. El modelo se prepara sobre los datos de entrenamiento llamando a la función fit(). Se pueden hacer predicciones llamando a la función predict() y especificando el índice de la hora u horas a predecir. Comencemos con algo simple. Ajustaremos un modelo ARIMA a todo el conjunto de datos de Shampoo Sales y revisaremos los errores residuales.\n",
    "\n",
    "Primero, ajustamos un modelo ARIMA (5,1,0). Esto establece el valor de retraso en 5 para la autorregresión (AR), usa un orden de diferencia de 1 para hacer estacionarias las series de tiempo y usa un modelo de promedio móvil de 0.\n",
    "\n",
    "Al ajustar el modelo, se proporciona mucha información de depuración sobre el ajuste del modelo de regresión lineal. Podemos desactivar esto estableciendo el argumento disp en 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA, ARMAResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(ts_log, order = (2,1,0)) #p,d,q para los modelos AR solo ocupamos p que en este caso es igual a 2, q=1 por ser la \n",
    "                                       #primera diferencia y 0 por ser un modelo AR \n",
    "#Fit para entrenar el modelo    \n",
    "results_AR = model.fit(disp = -1) #Al ajustar el modelo, se proporciona mucha información de depuración sobre el ajuste del \n",
    "                                  #modelo de regresión lineal.Podemos desactivar esto estableciendo el argumento disp en 0.\n",
    "\n",
    "plt.plot(ts_log_diff)\n",
    "plt.plot(results_AR.fittedvalues, color = 'red')\n",
    "plt.title('RSS: %.4f'% sum((results_AR.fittedvalues - ts_log_diff)**2)) #Residual sum of squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(ts_log, order= (0, 1, 2))  #p,d,q en este caso por ser modelo MA utilizamos los rezagos de error por lo que p=1,\n",
    "                                        #es un modelo de prime diferencia con q=2 por utilizar dos rezagos en el error\n",
    "#Fit para entrenar el modelo    \n",
    "results_MA = model.fit(disp = -1) #Al ajustar el modelo, se proporciona mucha información de depuración sobre el ajuste del \n",
    "                                  #modelo de regresión lineal.Podemos desactivar esto estableciendo el argumento disp en 0. \n",
    "\n",
    "\n",
    "plt.plot(ts_log_diff)\n",
    "plt.plot(results_MA.fittedvalues, color= 'red')\n",
    "plt.title('RSS: %.4f'% sum((results_MA.fittedvalues - ts_log_diff)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combined Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(ts_log, order = (2, 1, 2))  #p,d,q \n",
    "#Fit para entrenar el modelo \n",
    "results_ARIMA = model.fit(disp = -1)#Al ajustar el modelo, se proporciona mucha información de depuración sobre el ajuste del \n",
    "                                  #modelo de regresión lineal.Podemos desactivar esto estableciendo el argumento disp en 0.\n",
    "\n",
    "plt.plot(ts_log_diff)\n",
    "plt.plot(results_ARIMA.fittedvalues, color= 'red')\n",
    "plt.title('RSS: %.4f'% sum((results_ARIMA.fittedvalues - ts_log_diff)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutando el ejemplo imprime un resumen del modelo ajustado. Esto resume los valores de los coeficientes utilizados, así como la habilidad del ajuste en las observaciones de la muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, obtenemos un plot de los errores residuales, lo que sugiere que todavía puede haber alguna información de tendencia que el modelo no capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot residual errors\n",
    "residuals = pd.DataFrame(model_fit.resid)\n",
    "residuals.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, obtenemos un plot de densidad de los valores de error residual, lo que sugiere que los errores son gaussianos, pero pueden no estar centrados en cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals.plot(kind='kde')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestra la distribución de los errores residuales. Los resultados muestran que, de hecho, hay un sesgo en la predicción (una media distinta de cero en los residuos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenga en cuenta que, aunque anteriormente utilizamos todo el conjunto de datos para el análisis de series de tiempo, idealmente realizaríamos este análisis solo en el conjunto de datos de entrenamiento al desarrollar un modelo predictivo.\n",
    "\n",
    "A continuación, veamos cómo podemos usar el modelo ARIMA para hacer pronósticos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: We can split the training dataset into train and test sets, use the train set to fit the model, and generate a prediction for each element on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking it back to original scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_ARIMA_diff = pd.Series(results_ARIMA.fittedvalues, copy=True)\n",
    "predictions_ARIMA_diff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_ARIMA_diff_cumsum = predictions_ARIMA_diff.cumsum()\n",
    "predictions_ARIMA_diff_cumsum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_ARIMA_log = pd.Series(ts_log.iloc[0], index=ts_log.index)\n",
    "predictions_ARIMA_log = predictions_ARIMA_log.add(predictions_ARIMA_diff_cumsum,fill_value=0)\n",
    "predictions_ARIMA_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_ARIMA = np.exp(predictions_ARIMA_log)\n",
    "plt.plot(ts)\n",
    "plt.plot(predictions_ARIMA)\n",
    "plt.title('RMSE: %.4f'% np.sqrt(sum((predictions_ARIMA-ts)**2)/len(ts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validating Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain values for forecasts of the time series from #year\n",
    "pred = results.get_prediction(start = pd.to_datetime('1958-01-01'), dynamic = False)\n",
    "#Obtain associated confidence intervals for forecasts of the time series\n",
    "pred_ci = pred.conf_int()\n",
    "pred_ci.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The dynamic = False argument ensures that we produce one-step ahead forecasts, meaning that forecasts at each point are generated using the full history up to that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the forecasted values with historical data\n",
    "ax = ts_log['1953':].plot(label = 'observed')\n",
    "pred.predicted_mean.plot(ax = ax, label = 'One-step ahead forecast', alpha = 0.7)\n",
    "ax.fill_between(pred_ci.index, pred_ci.iloc[:, 0], pred_ci.iloc[:, 1], color = 'k', alpha = .2)\n",
    "ax.fill_betweenx(ax.get_ylim(), pd.to_datetime('1958-01-01'), ts_log.index[-1], alpha = .1, zorder = -1)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('ts_log')\n",
    "plt.title('Simple')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.predicted_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log_forecasted = pred.predicted_mean     #From 1958 to 1960 (validation process)\n",
    "ts_log_original = ts_log['1958-01-01':]\n",
    "mse = ((ts_log_forecasted - ts_log_original) ** 2).mean()  #Mean square error\n",
    "print('Mean Squared Error of forecast : {}'.format(round(mse,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean square error is almost zero. This means our prediction is very accurate.\n",
    "\n",
    "However, a better representation of our true predictive power can be obtained using dynamic forecasts. In this case, we only use information from the time series up to a certain point, and after that, forecasts are generated using values from previous forecasted time points. Let's try with computing the dynamic forecast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take exponential function\n",
    "pred_uc = np.exp(pred_uc.predicted_mean)\n",
    "pred_ci = np.exp(pred_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot original data prediction\n",
    "ax = ts['1955':].plot(label='Observed')\n",
    "pred_uc.plot(ax=ax, label='Forecast')\n",
    "ax.fill_between(pred_ci.index, pred_ci.iloc[:, 0], pred_ci.iloc[:, 1], color='k', alpha=.25)\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('ts (Passengers)')\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
